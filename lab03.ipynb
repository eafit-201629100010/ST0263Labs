
from pyspark.sql import SparkSession

spark=SparkSession.builder.appName('data_processing').getOrCreate()
datos=spark.read.csv('s3://aws-logs-653067803131-us-east-1/datasets/spark/Casos_positivos_de_COVID-19_en_Colombia.csv',inferSchema=True,header=True)

#Imprimo las columnas
datos.columns

#Eliminación de columna (Copia del dataset sin una columna en específico)
datos_new=datos.drop('Edad')

#eliminación de otra columna
datos_new_new = datos_new.drop('Sexo')

#Creo una tabla mediante sql (Temporal)
datos_new_new.registerTempTable('nueva_tabla')


#filtrado de datos (muertes totales (muestra municipio y edad)) (usando el dataset original)
datos.filter(datos['Fecha de muerte']!='null').select('Nombre municipio','Edad').show()

#filtrado de datos (casos en Cartagena de Indias - otro método)
datos.filter(datos['Nombre municipio'] == 'CARTAGENA').select('Edad','Sexo').show()

#Query (agrupación) Cantidad de casos en Antioquia
casos = datos.filter(datos['Nombre departamento'] == 'ANTIOQUIA').count()
print(casos)

#Query cantidad de casos por departamento
agrupados = datos.groupBy('Nombre departamento')
agrupados.count().show()

